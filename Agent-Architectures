{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T00:09:49.310971Z","iopub.execute_input":"2025-11-10T00:09:49.311455Z","iopub.status.idle":"2025-11-10T00:09:49.318273Z","shell.execute_reply.started":"2025-11-10T00:09:49.311421Z","shell.execute_reply":"2025-11-10T00:09:49.316478Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"### Section 1\n\n## ‚öôÔ∏è Setup\n\n### Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:41:53.705947Z","iopub.execute_input":"2025-11-10T12:41:53.706240Z","iopub.status.idle":"2025-11-10T12:41:53.843468Z","shell.execute_reply.started":"2025-11-10T12:41:53.706217Z","shell.execute_reply":"2025-11-10T12:41:53.842580Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### 1.2 Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:41:57.683026Z","iopub.execute_input":"2025-11-10T12:41:57.683680Z","iopub.status.idle":"2025-11-10T12:42:39.105407Z","shell.execute_reply.started":"2025-11-10T12:41:57.683655Z","shell.execute_reply":"2025-11-10T12:42:39.104592Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"---\n### Section 2\n\n## ü§î Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:42:57.183403Z","iopub.execute_input":"2025-11-10T12:42:57.185028Z","iopub.status.idle":"2025-11-10T12:42:57.191393Z","shell.execute_reply.started":"2025-11-10T12:42:57.184995Z","shell.execute_reply":"2025-11-10T12:42:57.190099Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:43:05.020054Z","iopub.execute_input":"2025-11-10T12:43:05.020373Z","iopub.status.idle":"2025-11-10T12:43:05.025580Z","shell.execute_reply.started":"2025-11-10T12:43:05.020351Z","shell.execute_reply":"2025-11-10T12:43:05.024717Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=\"gemini-2.5-flash-lite\",\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[\n        AgentTool(research_agent),\n        AgentTool(summarizer_agent)\n    ],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:45:25.528992Z","iopub.execute_input":"2025-11-10T12:45:25.529319Z","iopub.status.idle":"2025-11-10T12:45:25.535174Z","shell.execute_reply.started":"2025-11-10T12:45:25.529296Z","shell.execute_reply":"2025-11-10T12:45:25.534226Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"What are the latest advancements in Vedanta and what do they mean for development of AI?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:45:30.160044Z","iopub.execute_input":"2025-11-10T12:45:30.160355Z","iopub.status.idle":"2025-11-10T12:45:39.215476Z","shell.execute_reply.started":"2025-11-10T12:45:30.160331Z","shell.execute_reply":"2025-11-10T12:45:39.214730Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in Vedanta and what do they mean for development of AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The latest advancements at Vedanta are heavily focused on integrating AI and smart technologies to become an AI-first company, with significant implications for AI development, particularly in industrial contexts.\n\nKey advancements include:\n\n*   **Enhanced Industrial Safety and Efficiency:** AI is being used for real-time safety surveillance through AI cameras and smart helmets, leading to fewer incidents. Predictive maintenance of machinery and process optimization are also key areas, driving AI development in sensor data analysis, anomaly detection, and digital twins.\n*   **Autonomous Operations and Monitoring:** AI-powered drones are employed for real-time monitoring of areas like blast zones, enhancing safety and reducing manual inspections. This pushes AI in autonomous navigation and real-time data processing.\n*   **Sustainability and Emissions Management:** Vedanta is using AI for carbon monitoring, emissions forecasting, and supply chain optimization to achieve net-zero goals, advancing AI in environmental impact assessment and resource management.\n*   **Immersive Workforce Training:** AI-enhanced VR simulators are being used for training employees, improving skill development and reducing risks.\n*   **Collaborative Innovation:** Through its \\\"Spark\\\" platform, Vedanta is partnering with startups to deploy AI solutions, fostering the practical application and refinement of AI technologies in diverse business sectors.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n### Section 3\n## üö• Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:46:21.988833Z","iopub.execute_input":"2025-11-10T12:46:21.989130Z","iopub.status.idle":"2025-11-10T12:46:21.994882Z","shell.execute_reply.started":"2025-11-10T12:46:21.989110Z","shell.execute_reply":"2025-11-10T12:46:21.993893Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\", # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:46:27.953582Z","iopub.execute_input":"2025-11-10T12:46:27.953944Z","iopub.status.idle":"2025-11-10T12:46:27.959440Z","shell.execute_reply.started":"2025-11-10T12:46:27.953920Z","shell.execute_reply":"2025-11-10T12:46:27.958630Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\", # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:46:31.740019Z","iopub.execute_input":"2025-11-10T12:46:31.740885Z","iopub.status.idle":"2025-11-10T12:46:31.746801Z","shell.execute_reply.started":"2025-11-10T12:46:31.740854Z","shell.execute_reply":"2025-11-10T12:46:31.745264Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:46:36.276588Z","iopub.execute_input":"2025-11-10T12:46:36.277202Z","iopub.status.idle":"2025-11-10T12:46:36.282080Z","shell.execute_reply.started":"2025-11-10T12:46:36.277174Z","shell.execute_reply":"2025-11-10T12:46:36.281173Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Write a blog post about the benefits of multi-agent systems for software developers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:46:40.727304Z","iopub.execute_input":"2025-11-10T12:46:40.727643Z","iopub.status.idle":"2025-11-10T12:46:47.866843Z","shell.execute_reply.started":"2025-11-10T12:46:40.727621Z","shell.execute_reply":"2025-11-10T12:46:47.866091Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Here's a blog outline on the benefits of multi-agent systems for software developers:\n\n## Headline: Level Up Your Code: How Multi-Agent Systems Are Revolutionizing Software Development\n\n**Introduction Hook:** Imagine a team of intelligent, specialized assistants working tirelessly on your software projects. That's the promise of multi-agent systems (MAS), a paradigm shift that's empowering developers to build more robust, efficient, and intelligent applications. Ready to see how?\n\n### Section 1: Enhanced Problem Solving and Complexity Management\n\n*   **Decomposition of Complex Tasks:** MAS allows you to break down large, daunting problems into smaller, manageable tasks, each handled by an agent with specific expertise. This makes even the most intricate software challenges approachable.\n*   **Distributed Intelligence:** Instead of a monolithic system, MAS distributes intelligence across multiple agents. This leads to more resilient systems where the failure of one agent doesn't cripple the entire application.\n*   **Parallel Processing and Efficiency:** Agents can work concurrently on different parts of a problem, significantly speeding up development and execution times. This is crucial for real-time applications and large-scale data processing.\n\n### Section 2: Improved Modularity, Reusability, and Maintainability\n\n*   **Independent Agent Development:** Each agent can be developed, tested, and updated independently. This modular approach streamlines the development lifecycle and reduces the risk of introducing bugs in other parts of the system.\n*   **Encouraging Reusable Components:** Well-defined agents with specific functionalities become natural building blocks. These agents can be reused across different projects, saving significant development effort and promoting best practices.\n*   **Easier Debugging and Maintenance:** When a problem arises, developers can pinpoint the problematic agent rather than sifting through massive codebases. This makes debugging faster and maintenance less of a chore.\n\n### Section 3: Enabling Sophisticated AI and Intelligent Features\n\n*   **Autonomous and Adaptive Behavior:** MAS allows for the creation of systems that can learn, adapt, and make decisions autonomously. This is the backbone of advanced AI applications like intelligent assistants, autonomous vehicles, and sophisticated simulation environments.\n*   **Cooperative and Competitive Interactions:** Agents can be designed to collaborate to achieve common goals or compete to optimize outcomes. This opens doors for complex simulations, game development, and advanced optimization algorithms.\n*   **Emergent Behavior:** The interaction of simple agents can lead to complex, intelligent, and often unpredictable \"emergent\" behavior. This allows for the creation of systems that can handle unforeseen situations and exhibit surprising capabilities.\n\n### Section 4: Future-Proofing Your Development Skills\n\n*   **Growing Demand in AI and Robotics:** The fields of Artificial Intelligence and Robotics are increasingly relying on MAS. Developing expertise in this area positions you at the forefront of innovation.\n*   **New Architectural Possibilities:** MAS offers a fundamentally different way to think about software architecture, moving away from traditional monolithic or microservice approaches for certain problems.\n*   **Solving Tomorrow's Challenges:** As software systems become more interconnected and intelligent, MAS provides the tools and frameworks to build the solutions for future complexities.\n\n**Concluding Thought:** Multi-agent systems aren't just a theoretical concept; they are a practical and powerful approach to software development that offers tangible benefits. By embracing MAS, you can unlock new levels of efficiency, intelligence, and adaptability in your projects, ultimately making you a more valuable and future-ready developer.\nWriterAgent > ## Level Up Your Code: How Multi-Agent Systems Are Revolutionizing Software Development\n\nImagine a team of intelligent, specialized assistants working tirelessly on your software projects. That's the promise of multi-agent systems (MAS), a paradigm shift empowering developers to build more robust, efficient, and intelligent applications. Ready to see how?\n\nMAS excels at **enhanced problem-solving and complexity management**. Think of breaking down those massive, daunting tasks into smaller, manageable ones, each handled by an agent with specific expertise. This distributed intelligence makes your systems more resilient; the failure of one agent doesn't cripple the whole. Plus, with agents working concurrently, you‚Äôll see significant speedups in both development and execution.\n\nBeyond efficiency, MAS champions **improved modularity, reusability, and maintainability**. Each agent can be developed, tested, and updated independently, streamlining your workflow and reducing bugs. These specialized agents become reusable components, saving you time and effort across projects. When issues arise, debugging becomes a breeze ‚Äì pinpoint the problematic agent, not an entire codebase.\n\nFurthermore, MAS unlocks **sophisticated AI and intelligent features**. You can create systems that learn, adapt, and make decisions autonomously, powering everything from intelligent assistants to autonomous vehicles. Agents can collaborate for common goals or compete to optimize outcomes, opening doors for complex simulations and advanced algorithms.\n\nEmbracing MAS is also about **future-proofing your skills**. As AI and robotics grow, so does the demand for MAS expertise. This approach offers novel architectural possibilities, moving beyond traditional models. By adopting MAS, you're equipping yourself to tackle tomorrow's complex, interconnected, and intelligent software challenges, making you a more valuable and future-ready developer.\nEditorAgent > ## Level Up Your Code: How Multi-Agent Systems Are Revolutionizing Software Development\n\nImagine a team of intelligent, specialized assistants working tirelessly on your software projects. That's the promise of multi-agent systems (MAS), a paradigm shift empowering developers to build more robust, efficient, and intelligent applications. Ready to see how?\n\n### Enhanced Problem-Solving and Complexity Management\n\nMAS excels at tackling complex challenges. Think of breaking down massive, daunting tasks into smaller, manageable ones, with each handled by an agent possessing specific expertise. This distributed intelligence makes your systems more resilient; the failure of one agent doesn't cripple the entire application. Furthermore, with agents working concurrently, you'll experience significant speedups in both development and execution.\n\n### Improved Modularity, Reusability, and Maintainability\n\nBeyond efficiency, MAS champions enhanced modularity, reusability, and maintainability. Each agent can be developed, tested, and updated independently, streamlining your workflow and reducing bugs. These specialized agents become reusable components, saving you time and effort across projects. When issues arise, debugging becomes a breeze ‚Äì you can pinpoint the problematic agent, not an entire codebase.\n\n### Sophisticated AI and Intelligent Features\n\nMAS unlocks the potential for sophisticated AI and intelligent features. You can create systems that learn, adapt, and make decisions autonomously, powering everything from intelligent assistants to autonomous vehicles. Agents can collaborate for common goals or compete to optimize outcomes, opening doors for complex simulations and advanced algorithms.\n\n### Future-Proofing Your Development Skills\n\nEmbracing MAS is also about future-proofing your career. As AI and robotics continue to grow, so does the demand for MAS expertise. This approach offers novel architectural possibilities, moving beyond traditional models. By adopting MAS, you're equipping yourself to tackle tomorrow's complex, interconnected, and intelligent software challenges, making you a more valuable and future-ready developer.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n### Section 4\n## üõ£Ô∏è Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:47:09.865941Z","iopub.execute_input":"2025-11-10T12:47:09.866269Z","iopub.status.idle":"2025-11-10T12:47:09.871505Z","shell.execute_reply.started":"2025-11-10T12:47:09.866246Z","shell.execute_reply":"2025-11-10T12:47:09.870599Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\", # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:47:13.470545Z","iopub.execute_input":"2025-11-10T12:47:13.470844Z","iopub.status.idle":"2025-11-10T12:47:13.475959Z","shell.execute_reply.started":"2025-11-10T12:47:13.470823Z","shell.execute_reply":"2025-11-10T12:47:13.475093Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\", # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:47:16.575075Z","iopub.execute_input":"2025-11-10T12:47:16.575706Z","iopub.status.idle":"2025-11-10T12:47:16.580380Z","shell.execute_reply.started":"2025-11-10T12:47:16.575682Z","shell.execute_reply":"2025-11-10T12:47:16.579446Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\", # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:47:20.002283Z","iopub.execute_input":"2025-11-10T12:47:20.002888Z","iopub.status.idle":"2025-11-10T12:47:20.007856Z","shell.execute_reply.started":"2025-11-10T12:47:20.002863Z","shell.execute_reply":"2025-11-10T12:47:20.007111Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:47:24.654289Z","iopub.execute_input":"2025-11-10T12:47:24.655055Z","iopub.status.idle":"2025-11-10T12:47:24.659986Z","shell.execute_reply.started":"2025-11-10T12:47:24.655026Z","shell.execute_reply":"2025-11-10T12:47:24.659252Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Run the daily executive briefing on Tech, Health, and Finance\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:47:28.639970Z","iopub.execute_input":"2025-11-10T12:47:28.640779Z","iopub.status.idle":"2025-11-10T12:47:36.121456Z","shell.execute_reply.started":"2025-11-10T12:47:28.640750Z","shell.execute_reply":"2025-11-10T12:47:36.120567Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nTechResearcher > **Key AI/ML Trends for 2025:**\n\n1.  **Generative AI Expansion:** Beyond text, generative AI is now creating diverse content like images, video, and music, accelerating artistic expression and practical applications. Companies like Google (Imagen, Muse) and OpenAI are at the forefront.\n2.  **Shift to Smaller, Specialized Models (SLMs):** The focus is moving from large language models (LLMs) to smaller, more efficient models tailored for specific industries and tasks, improving performance and reducing costs.\n3.  **Explainable AI (XAI) and Ethics:** As AI becomes more integrated, transparency and ethical considerations are paramount. XAI aims to make AI decision-making understandable, fostering trust and compliance, especially in sensitive sectors like healthcare and finance.\n\n**Major Companies Involved:** Leading companies include Google, OpenAI, Microsoft, NVIDIA, Amazon, Databricks, and Anthropic. NVIDIA's GPUs are crucial for AI computation, while cloud providers like Google Cloud and AWS offer extensive AI services.\n\n**Potential Impact:** These trends promise enhanced automation, personalized customer experiences, accelerated innovation in research and development, and significant efficiency gains across industries. However, challenges like data privacy, potential job displacement, and the environmental impact of AI compute power need careful consideration.\nHealthResearcher > Here's a concise briefing on recent breakthroughs in Tech, Health, and Finance:\n\n**Health:** mRNA vaccine technology, pioneered with COVID-19 vaccines, is rapidly expanding to applications like cancer and Zika virus. Lab-grown blood, successfully transfused in trials, promises to revolutionize treatments for blood disorders. Advanced Alzheimer's treatments like Leqemab, targeting amyloid plaques, are offering new hope. These advancements are largely available now or in late-stage trials.\n\n**Tech:** AI and machine learning continue to drive innovation, powering everything from virtual assistants to complex automation. The widespread adoption of 5G networks enhances connectivity for real-time applications. Augmented and Virtual Reality (AR/VR) are transforming gaming, education, and training, with potential for seamless integration of virtual and real worlds. These are currently being implemented and rapidly evolving.\n\n**Finance:** Embedded finance is integrating financial services into non-financial platforms, with significant projected growth by 2026. Decentralized Finance (DeFi) is maturing with enhanced security and scalability. AI is increasingly vital, projected to more than double its market value in financial services by 2029. Biometric and voice-activated payments are becoming mainstream. These trends are actively shaping the financial landscape now.\nFinanceResearcher > **Tech Trends:**\n\n1.  **Agentic AI and Context Engineering:** AI systems are moving beyond simple responses to autonomously perform complex tasks. Context engineering, the practice of structuring information for AI, is crucial for reliable performance. This trend is reshaping infrastructure orchestration due to increased AI workload demands.\n    *   **Market Implications:** Increased automation, efficiency in complex processes, and a need for robust AI infrastructure.\n    *   **Future Outlook:** Expect more sophisticated AI agents capable of multi-step workflows and deeper integration into business operations.\n\n2.  **5G Expansion and Quantum Computing Advancements:** The continued rollout of 5G promises faster speeds, while quantum computing progresses towards practical applications in fields like finance and manufacturing.\n    *   **Market Implications:** Enhanced connectivity, new possibilities for data-intensive industries, and potential for breakthroughs in scientific research and complex problem-solving.\n    *   **Future Outlook:** 5G will enable new phygital experiences, and quantum computing could revolutionize optimization, simulation, and cryptography.\n\n3.  **Semiconductor Evolution:** Driven by AI and evolving market dynamics, semiconductor technology is seeing significant advancements, including more efficient chip designs.\n    *   **Market Implications:** More powerful and energy-efficient devices, supporting the growth of AI and other data-intensive technologies.\n    *   **Future Outlook:** Continued competition and innovation in chip manufacturing will be critical for the advancement of all technology sectors.\n\n**Health Trends:**\n\n1.  **Functional Foods and Gut Health Focus:** Consumers are increasingly seeking foods that offer specific health benefits, particularly for digestive health, with functional ingredients like probiotics and adaptogens gaining popularity.\n    *   **Market Implications:** Growth in specialized food products, increased demand for ingredients supporting gut health, and a shift towards food as preventative medicine.\n    *   **Future Outlook:** Personalized nutrition and a greater emphasis on the link between diet and overall well-being.\n\n2.  **Strength Training and High Protein Diets:** There's a notable shift towards strength training over cardio for overall health, coupled with a growing emphasis on high-protein diets for satiety, metabolic health, and weight management.\n    *   **Market Implications:** Increased demand for protein-rich food products and supplements, growth in fitness programs focusing on strength, and a potential rise in \"high-protein\" convenience foods.\n    *   **Future Outlook:** Continued focus on protein intake, but with an increasing awareness of protein quality and the potential downsides of highly processed \"protein-enhanced\" foods.\n\n3.  **Healthy Aging and Preventative Healthcare:** A growing number of individuals, including younger generations, are prioritizing proactive health measures for longevity, cognitive function, and vitality.\n    *   **Market Implications:** Expansion of products and services focused on anti-aging, cognitive support, and early disease prevention, including telemedicine and digital health monitoring.\n    *   **Future Outlook:** Greater integration of technology in health management and a sustained focus on preventative care across all age groups.\n\n**Finance Trends:**\n\n1.  **AI Integration in Financial Systems:** Artificial intelligence is becoming increasingly embedded in financial operations, from AI workloads demanding new infrastructure orchestration to the development of agentic AI for financial tasks.\n    *   **Market Implications:** Enhanced decision-making, improved fraud detection, personalized financial advice, and a demand for skilled professionals in AI and data science.\n    *   **Future Outlook:** Deeper AI-driven automation and predictive capabilities across all financial services, potentially leading to new business models.\n\n2.  **Banking Consolidation and Mega Mergers:** In regions like India, there's a government-led push towards consolidating banks to create larger, more competitive institutions.\n    *   **Market Implications:** Increased efficiency in the banking sector, potential for greater lending capacity, and a reshaped competitive landscape.\n    *   **Future Outlook:** Continued M&A activity in the financial sector globally, aiming for scale and resilience.\n\n3.  **Economic Volatility and Policy Shifts:** Global markets are experiencing volatility, influenced by factors like inflation trends, potential central bank policy shifts (e.g., interest rate changes), and geopolitical events.\n    *   **Market Implications:** Investor caution, demand for inflation hedges, and a need for sophisticated risk management strategies. Market participants are closely watching economic data and central bank communications.\n    *   **Future Outlook:** Continued uncertainty may lead to mixed market performance, with a focus on data-driven investment decisions and adaptable strategies.\nAggregatorAgent > Here's an executive summary combining the research findings:\n\n**Executive Summary: Cross-Sector Innovation and Integration**\n\nAcross technology, health, and finance, Artificial Intelligence (AI) is the unifying force driving transformative change. Generative AI is expanding its capabilities beyond text to create diverse content, while smaller, specialized AI models are optimizing efficiency. Agentic AI, capable of complex autonomous tasks, is reshaping operations and demanding new infrastructure. Explainable AI (XAI) is becoming critical for trust and compliance, especially in sensitive sectors like finance and healthcare.\n\nIn health, mRNA technology is finding new applications beyond COVID-19, with promising advancements in cancer and Zika virus treatments. Lab-grown blood and novel Alzheimer's treatments are offering revolutionary therapeutic options, often available now or in late-stage trials. Complementing these medical breakthroughs, consumer health trends emphasize functional foods for gut health, high-protein diets, and proactive, healthy aging strategies, integrating preventative care with technology.\n\nFinance is witnessing significant disruption through embedded finance, maturing DeFi, and the widespread adoption of biometric payments. AI integration is profoundly impacting financial systems, enhancing decision-making, fraud detection, and personalization, while also creating demand for specialized infrastructure. This rapid technological evolution occurs against a backdrop of economic volatility and global policy shifts, underscoring the need for adaptability and sophisticated risk management across all sectors. The continued expansion of 5G and advancements in semiconductors further support these integrated trends.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n### Section 5\n## ‚û∞ Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\", # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:48:28.957235Z","iopub.execute_input":"2025-11-10T12:48:28.957650Z","iopub.status.idle":"2025-11-10T12:48:28.962950Z","shell.execute_reply.started":"2025-11-10T12:48:28.957623Z","shell.execute_reply":"2025-11-10T12:48:28.961976Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\", # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:48:33.781892Z","iopub.execute_input":"2025-11-10T12:48:33.782177Z","iopub.status.idle":"2025-11-10T12:48:33.786872Z","shell.execute_reply.started":"2025-11-10T12:48:33.782157Z","shell.execute_reply":"2025-11-10T12:48:33.785945Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:48:42.671035Z","iopub.execute_input":"2025-11-10T12:48:42.671344Z","iopub.status.idle":"2025-11-10T12:48:42.676637Z","shell.execute_reply.started":"2025-11-10T12:48:42.671319Z","shell.execute_reply":"2025-11-10T12:48:42.675814Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    \n    output_key=\"current_story\", # It overwrites the story with the new, refined version.\n    tools=[FunctionTool(exit_loop)], # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:48:49.540141Z","iopub.execute_input":"2025-11-10T12:48:49.540802Z","iopub.status.idle":"2025-11-10T12:48:49.546562Z","shell.execute_reply.started":"2025-11-10T12:48:49.540778Z","shell.execute_reply":"2025-11-10T12:48:49.545403Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2, # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:48:55.545300Z","iopub.execute_input":"2025-11-10T12:48:55.545957Z","iopub.status.idle":"2025-11-10T12:48:55.551332Z","shell.execute_reply.started":"2025-11-10T12:48:55.545934Z","shell.execute_reply":"2025-11-10T12:48:55.550371Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Write a short story about a Girl who buys a beautiful small pineapple conure\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:49:53.207718Z","iopub.execute_input":"2025-11-10T12:49:53.208062Z","iopub.status.idle":"2025-11-10T12:50:00.411005Z","shell.execute_reply.started":"2025-11-10T12:49:53.208040Z","shell.execute_reply":"2025-11-10T12:50:00.410188Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a Girl who buys a beautiful small pineapple conure\nInitialWriterAgent > Maya‚Äôs heart fluttered the moment she saw him. Perched regally on a dowel, a miniature sunbeam with wings, was the most beautiful pineapple conure she‚Äôd ever laid eyes on. His emerald green body was splashed with vibrant yellow and fiery orange across his chest and crown, like a sunset captured. He tilted his head, a curious glint in his intelligent dark eyes, as if assessing her.\n\n‚ÄúHe‚Äôs a special one,‚Äù the pet shop owner murmured. Maya was already lost. She reached out a finger, and he tentatively stepped onto it, his tiny claws a gentle pressure. A soft chirp, like a musical question, escaped him. That was it. She was buying him. She‚Äôd named him Pip before she even left the store.\nCriticAgent > The story has a strong emotional opening and a clear, immediate goal for the character. The descriptive language for the bird is excellent. However, the story feels very short and abrupt, like the beginning of something larger.\n\nHere are a few suggestions for improvement:\n\n1.  **Develop the interaction and connection:** While the initial step onto the finger is a good start, consider adding a few more moments that solidify Maya's connection with Pip. Perhaps he nips gently, preens a feather on her finger, or makes a more complex sound. This would further justify her immediate decision to buy him and make their bond feel more earned.\n2.  **Show, don't just tell, Maya's feelings:** The phrase \"Maya was already lost\" tells us she's smitten, but showing it would be more impactful. How does her expression change? Does she forget her surroundings? Does she feel a sense of calm or excitement that overpowers her usual decision-making process?\n3.  **Consider expanding the \"after\" moment:** The story ends as she's leaving the store. What happens on the car ride home? What is her initial impression of Pip in a new environment? Even a few more sentences could provide a more satisfying sense of conclusion for this vignette, or it could serve as a stronger hook if this is intended to be the beginning of a longer piece.\nRefinerAgent > Maya‚Äôs heart fluttered the moment she saw him. Perched regally on a dowel, a miniature sunbeam with wings, was the most beautiful pineapple conure she‚Äôd ever laid eyes on. His emerald green body was splashed with vibrant yellow and fiery orange across his chest and crown, like a sunset captured. He tilted his head, a curious glint in his intelligent dark eyes, as if assessing her.\n\n‚ÄúHe‚Äôs a special one,‚Äù the pet shop owner murmured, his voice a low rumble that barely registered in Maya's ears. She felt a warmth spread through her chest, a giddy excitement bubbling up that made her usually pragmatic mind fuzzy. Her eyes softened, a gentle smile gracing her lips as she forgot the bustling shop around her, her entire world narrowing to the exquisite creature before her. She reached out a finger, and he tentatively stepped onto it, his tiny claws a gentle pressure against her skin. He nibbled softly at her cuticle, a playful, inquisitive gesture, before letting out a soft chirp, like a musical question. Then, as if making a decision, he snuggled closer, preening a stray feather on her finger with his beak. That was it. She was buying him. She‚Äôd named him Pip before she even left the store.\n\nThe car ride home was a symphony of quiet chirps and Maya‚Äôs soft reassurances. Pip sat on her shoulder, occasionally nibbling her earlobe, his vibrant colors a stark contrast against her dark jacket. He seemed unfazed by the new surroundings, exploring her hair with his beak and making little contented noises. Maya kept glancing at him in the rearview mirror, her heart swelling with a protective affection she hadn't anticipated. This wasn't just a pet; it was a connection, a tiny spark of joy that had somehow found its way into her life. As they pulled into her driveway, Maya knew her life had just become a lot more colorful.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n### Section 6\n## Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"code","source":"import threading\nimport time\n\n# Define basic task agents\n\nclass Agent:\n    def run(self, data):\n        raise NotImplementedError\n\nclass AgentA(Agent):\n    def run(self, data):\n        print(\"[A] Processing:\", data)\n        time.sleep(1)\n        return data + \"->A\"\n\nclass AgentB(Agent):\n    def run(self, data):\n        print(\"[B] Processing:\", data)\n        time.sleep(1)\n        return data + \"->B\"\n\nclass AgentC(Agent):\n    def run(self, data):\n        print(\"[C] Processing:\", data)\n        time.sleep(1)\n        return data + \"->C\"\n\n# SequentialAgent: Fixed pipeline (A -> B -> C)\ndef sequential_workflow(data):\n    print(\"\\nSequentialAgent:\")\n    a = AgentA()\n    b = AgentB()\n    c = AgentC()\n    x = a.run(data)\n    x = b.run(x)\n    x = c.run(x)\n    print(\"Result:\", x)\n\n# ParallelAgent: Run all at once\ndef parallel_workflow(data):\n    print(\"\\nParallelAgent:\")\n    results = {}\n    def run_agent(agent_class, name):\n        agent = agent_class()\n        results[name] = agent.run(data)\n\n    threads = [\n        threading.Thread(target=run_agent, args=(AgentA, \"A\")),\n        threading.Thread(target=run_agent, args=(AgentB, \"B\")),\n        threading.Thread(target=run_agent, args=(AgentC, \"C\")),\n    ]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n    print(\"Results:\", results)\n\n# LoopAgent: Iterative refinement between two agents\ndef loop_workflow(data, iterations=3):\n    print(\"\\nLoopAgent:\")\n    a = AgentA()\n    b = AgentB()\n    x = data\n    for i in range(iterations):\n        x = a.run(x)\n        x = b.run(x)\n    print(\"Refined Result:\", x)\n\n# LLM Orchestrator (basic): Uses logic to choose which agent to run\ndef llm_orchestrator_workflow(data):\n    print(\"\\nLLM Orchestrator:\")\n    # Let's \"decide\" which agent to pick based on the data length\n    if len(data) % 3 == 0:\n        x = AgentA().run(data)\n    elif len(data) % 3 == 1:\n        x = AgentB().run(data)\n    else:\n        x = AgentC().run(data)\n    print(\"Orchestrated Result:\", x)\n\n# --- Run all patterns ---\ninit_data = \"input\"\nsequential_workflow(init_data)\nparallel_workflow(init_data)\nloop_workflow(init_data, iterations=2)\nllm_orchestrator_workflow(init_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:56:01.594703Z","iopub.execute_input":"2025-11-10T12:56:01.595042Z","iopub.status.idle":"2025-11-10T12:56:10.610073Z","shell.execute_reply.started":"2025-11-10T12:56:01.595017Z","shell.execute_reply":"2025-11-10T12:56:10.609250Z"}},"outputs":[{"name":"stdout","text":"\nSequentialAgent:\n[A] Processing: input\n[B] Processing: input->A\n[C] Processing: input->A->B\nResult: input->A->B->C\n\nParallelAgent:\n[A] Processing: input\n[B] Processing: input\n[C] Processing: input\nResults: {'A': 'input->A', 'B': 'input->B', 'C': 'input->C'}\n\nLoopAgent:\n[A] Processing: input\n[B] Processing: input->A\n[A] Processing: input->A->B\n[B] Processing: input->A->B->A\nRefined Result: input->A->B->A->B\n\nLLM Orchestrator:\n[C] Processing: input\nOrchestrated Result: input->C\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"Here‚Äôs a simple multi-agent FAQ assistant for customer service that you can run in a Kaggle Python notebook. This demo uses a basic workflow and does not require external libraries except for sklearn (for classification) and basic Python.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfaq_data = [\n    {\"question\": \"How can I track my order?\", \"answer\": \"You can track your order with the tracking link sent to your email.\"},\n    {\"question\": \"How do I return a product?\", \"answer\": \"You can initiate a return from your account under 'Order History'.\"},\n    {\"question\": \"What are the shipping options?\", \"answer\": \"We offer standard, express, and same-day delivery options.\"},\n    {\"question\": \"How do I contact support?\", \"answer\": \"You can contact support via our help center or call 1800-000-000.\"},\n]\n\ndef classify_query(user_query):\n    keywords = {\n        \"order\": \"order status\",\n        \"track\": \"order status\",\n        \"return\": \"returns\",\n        \"shipping\": \"shipping\",\n        \"ship\": \"shipping\",\n        \"contact\": \"support\",\n        \"support\": \"support\"\n    }\n    for word, label in keywords.items():\n        if word in user_query.lower():\n            return label\n    return \"unknown\"\n\ndef retrieve_faq(user_query, faq_data):\n    questions = [faq[\"question\"] for faq in faq_data]\n    vectorizer = TfidfVectorizer().fit(questions + [user_query])\n    vectors = vectorizer.transform(questions + [user_query])\n    sim = cosine_similarity(vectors[-1], vectors[:-1])\n    idx = sim.argmax()\n    score = sim[0, idx]\n    return faq_data[idx][\"answer\"] if score > 0.3 else None\n\ndef summarize_answer(answer):\n    return answer.split(\".\")[0] + \".\"\n\ndef escalate():\n    return \"Transferring to a human agent. We'll get back to you soon.\"\n\ndef faq_assistant(user_query):\n    label = classify_query(user_query)\n    answer = retrieve_faq(user_query, faq_data)\n    if answer:\n        summary = summarize_answer(answer)\n        return summary\n    else:\n        return escalate()\n\n# --- Command-line interface ---\nprint(\"Welcome to the FAQ assistant! Type 'exit' to quit.\")\nwhile True:\n    user_query = input(\"\\nAsk your question: \")\n    if user_query.lower() == \"exit\":\n        print(\"Goodbye!\")\n        break\n    reply = faq_assistant(user_query)\n    print(\"[Answer]:\", reply)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T13:05:11.044976Z","iopub.execute_input":"2025-11-10T13:05:11.046078Z","iopub.status.idle":"2025-11-10T13:08:54.095570Z","shell.execute_reply.started":"2025-11-10T13:05:11.046052Z","shell.execute_reply":"2025-11-10T13:08:54.094611Z"}},"outputs":[{"name":"stdout","text":"Welcome to the FAQ assistant! Type 'exit' to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nAsk your question:  Order status\n"},{"name":"stdout","text":"[Answer]: Transferring to a human agent. We'll get back to you soon.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nAsk your question:  contact support\n"},{"name":"stdout","text":"[Answer]: You can contact support via our help center or call 1800-000-000.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nAsk your question:  bye\n"},{"name":"stdout","text":"[Answer]: Transferring to a human agent. We'll get back to you soon.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nAsk your question:  goodbye\n"},{"name":"stdout","text":"[Answer]: Transferring to a human agent. We'll get back to you soon.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nAsk your question:  exit\n"},{"name":"stdout","text":"Goodbye!\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"Here‚Äôs a customer support FAQ agent with Gemini 2.5 Flash-Lite that maps to the decision tree patterns.","metadata":{}},{"cell_type":"code","source":"# 1. Setup: Install and authenticate\n!pip install google-generativeai\n\nimport google.generativeai as genai\n\n# Set your Google Gemini API Key (replace with your actual key in production!)\nGOOGLE_API_KEY = 'YOUR-GEMINI-API-KEY'  # NEVER share your API key!\ngenai.configure(api_key=GOOGLE_API_KEY)\n\n# 2. Sample FAQ data\nfaq_data = [\n    {\"question\": \"How can I track my order?\", \"answer\": \"Use your order ID on our Track Order page.\"},\n    {\"question\": \"How do I return a product?\", \"answer\": \"Go to Order History and select 'Return Product'.\"},\n    {\"question\": \"What are the shipping options?\", \"answer\": \"We offer standard, express, and next-day delivery.\"},\n    {\"question\": \"How do I contact support?\", \"answer\": \"Use our Help Center or call our support hotline.\"}\n]\n\n# 3. Gemini Flash-Lite model shortcut\nmodel = genai.GenerativeModel('gemini-2.5-flash-lite')\n\n# 4. Agent classes\ndef classify_query_llm(user_query):\n    prompt = f\"Classify this customer service question into one of these: 'order status', 'returns', 'shipping', 'support', or 'other'.\\nQuestion: {user_query}\\nCategory:\"\n    resp = model.generate_content(prompt)\n    return resp.text.strip().lower()\n\ndef retrieve_faq_llm(user_query):\n    best_match = None\n    max_score = 0\n    for faq in faq_data:\n        prompt = f\"How similar is this question: '{user_query}' to: '{faq['question']}'? Reply only with a score from 0 to 1.\"\n        score_resp = model.generate_content(prompt)\n        try:\n            score = float(score_resp.text.strip())\n            if score > max_score:\n                max_score = score\n                best_match = faq\n        except:\n            continue\n    return best_match[\"answer\"] if best_match and max_score > 0.3 else None\n\ndef summarize_answer_llm(answer):\n    prompt = f\"Summarize this customer service answer in one sentence: {answer}\"\n    resp = model.generate_content(prompt)\n    return resp.text.strip()\n\ndef escalate_llm(user_query):\n    prompt = f\"This customer query could not be answered from FAQs. Write a polite escalation response for: '{user_query}'\"\n    resp = model.generate_content(prompt)\n    return resp.text.strip()\n\n# 5. Agent patterns from decision tree\ndef sequential_agent(user_query):\n    print(\"SequentialAgent: Fixed pipeline\")\n    category = classify_query_llm(user_query)\n    print(\"Classified as:\", category)\n    answer = retrieve_faq_llm(user_query)\n    if answer:\n        summary = summarize_answer_llm(answer)\n        print(\"Answer:\", summary)\n        return summary\n    else:\n        esc = escalate_llm(user_query)\n        print(\"Escalating:\", esc)\n        return esc\n\nimport concurrent.futures\n\ndef parallel_agent(user_query):\n    print(\"ParallelAgent: Run retrieval, classification, and summarization together\")\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        fut1 = executor.submit(classify_query_llm, user_query)\n        fut2 = executor.submit(retrieve_faq_llm, user_query)\n        category = fut1.result()\n        answer = fut2.result()\n        if answer:\n            summary = summarize_answer_llm(answer)\n            print(\"Answer:\", summary)\n            return summary\n        else:\n            esc = escalate_llm(user_query)\n            print(\"Escalating:\", esc)\n            return esc\n\ndef loop_agent(user_query, iterations=2):\n    print(\"LoopAgent: Iterative refinement\")\n    answer = None\n    for i in range(iterations):\n        if i == 0 or not answer:\n            answer = retrieve_faq_llm(user_query)\n        else:\n            answer = summarize_answer_llm(answer)\n        print(f\"Iteration {i+1}:\", answer)\n    return answer if answer else escalate_llm(user_query)\n\ndef llm_orchestrator_agent(user_query):\n    print(\"LLM Orchestrator: Uses LLM for dynamic next-step decision\")\n    decision_prompt = (\n        f\"What should I do for customer query: '{user_query}'? \"\n        \"Reply 'classify', 'retrieve', 'summarize', or 'escalate'.\"\n    )\n    step = model.generate_content(decision_prompt).text.strip().lower()\n    print(\"LLM decision:\", step)\n    if step == \"classify\":\n        result = classify_query_llm(user_query)\n    elif step == \"retrieve\":\n        result = retrieve_faq_llm(user_query)\n    elif step == \"summarize\":\n        ans = retrieve_faq_llm(user_query)\n        result = summarize_answer_llm(ans) if ans else escalate_llm(user_query)\n    else:\n        result = escalate_llm(user_query)\n    print(\"Result:\", result)\n    return result\n\n# 6. CLI loop (or replace with UI code)\nprint(\"\\n--- Customer Service FAQ (Gemini Multi-Agent Demo) ---\")\nprint(\"Type your question! (Type 'exit' to quit)\")\n\nwhile True:\n    user_query = input(\"\\nYour Question: \")\n    if user_query.lower() == \"exit\":\n        print(\"Goodbye!\")\n        break\n    print(\"\\nWhich agent pattern? (sequential / parallel / loop / orchestrator)\")\n    pattern = input(\"Select agent: \").strip().lower()\n    if pattern == \"sequential\":\n        print(sequential_agent(user_query))\n    elif pattern == \"parallel\":\n        print(parallel_agent(user_query))\n    elif pattern == \"loop\":\n        print(loop_agent(user_query))\n    elif pattern == \"orchestrator\":\n        print(llm_orchestrator_agent(user_query))\n    else:\n        print(\"Unknown pattern. Please choose sequential / parallel / loop / orchestrator.\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**CLI Version**","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfaq_data = [\n    {\"question\": \"How can I track my order?\", \"answer\": \"You can track your order with the tracking link sent to your email.\"},\n    {\"question\": \"How do I return a product?\", \"answer\": \"You can initiate a return from your account under 'Order History'.\"},\n    {\"question\": \"What are the shipping options?\", \"answer\": \"We offer standard, express, and same-day delivery options.\"},\n    {\"question\": \"How do I contact support?\", \"answer\": \"You can contact support via our help center or call 1800-000-000.\"},\n]\n\ndef classify_query(user_query):\n    keywords = {\n        \"order\": \"order status\",\n        \"track\": \"order status\",\n        \"return\": \"returns\",\n        \"shipping\": \"shipping\",\n        \"ship\": \"shipping\",\n        \"contact\": \"support\",\n        \"support\": \"support\"\n    }\n    for word, label in keywords.items():\n        if word in user_query.lower():\n            return label\n    return \"unknown\"\n\ndef retrieve_faq(user_query, faq_data):\n    questions = [faq[\"question\"] for faq in faq_data]\n    vectorizer = TfidfVectorizer().fit(questions + [user_query])\n    vectors = vectorizer.transform(questions + [user_query])\n    sim = cosine_similarity(vectors[-1], vectors[:-1])\n    idx = sim.argmax()\n    score = sim[0, idx]\n    return faq_data[idx][\"answer\"] if score > 0.3 else None\n\ndef summarize_answer(answer):\n    return answer.split(\".\")[0] + \".\"\n\ndef escalate():\n    return \"Transferring to a human agent. We'll get back to you soon.\"\n\ndef faq_assistant(user_query):\n    label = classify_query(user_query)\n    answer = retrieve_faq(user_query, faq_data)\n    if answer:\n        summary = summarize_answer(answer)\n        return summary\n    else:\n        return escalate()\n\n# --- Command-line interface ---\nprint(\"Welcome to the FAQ assistant! Type 'exit' to quit.\")\nwhile True:\n    user_query = input(\"\\nAsk your question: \")\n    if user_query.lower() == \"exit\":\n        print(\"Goodbye!\")\n        break\n    reply = faq_assistant(user_query)\n    print(\"[Answer]:\", reply)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}